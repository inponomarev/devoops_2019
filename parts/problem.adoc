:backend: revealjs
:customcss: common.css

== Что имеем на входе?
[%step]
* Облачный провайдер - DigitalOcean

[.notes]
--
Почему мы не изобретаем все с нуля. Система, которую мы разрабатываем, имеет прототип.
Который был развернут как раз в DigitalOcean. Работал он недостаточно быстро -
при требовании реакции в пределах секунды мы имели примерно 7-8 секунд. Что для системы
мониторинга в реальном времени неприемлемо. Поэтому появилась необходимость в создании новой версии системы.
--

=== Что имеем на входе?
[%step]
* Terraform
** ~1000 строк провайдер-ориентированного кода
** ~100 виртуальных машин
** ~20 dns-записей

[.notes]
--
Инфраструктура первой версии системы (!)создавалась и поддерживалась с помощью терраформа.
Терраформом создавались виртуальные машины(около 100), днс-записи(около 20). Терраформ-стейт хранился
в консуле, который крутился в том же DigitalOcean.
--

=== Что имеем на входе?
[%step]
* Ansible
** ~5000 строк кода
** ~20 плейбуков с пачкой ролей

[.notes]
--
Но мало создать инфраструктуру. Чтобы безжизненные машины начали делать полезную работу,
надо наполнить их кодом. Причем не только своим - базы данных, прокси-серверы, прочие удовольствия,
не изобретать же их по-новой? Для разрешения этой задачи был использован ансибл. Почему? Да потому что
он невероятно прост в освоении, не требует агента, ходит на машины по ssh, и отлично журналируется.
--

== Что болит?
[%step]
* Нет быстрого способа переехать к другому провайдеру.
* МНОГО кода для деплоя
* Отвратительное масштабирование системы.
* Деплой тоже требует дебага.
* Кто ходил на мою ноду?

[.notes]
--
* Как я уже сказал, весь код в Terraform строго провайдер-ориентирован. Если мне необходимо заказать виртуальную машину,
то это всегда digitalocean_droplet. Если мне нужно заказать dns-запись - это всегда (!).
Случись задача переезда на другого облачного провайдера(по воле заказчика или закона), и весь код можно будет выбросить.
* Мы наслышаны о простоте Ansible, но многие упускают из внимания тот факт, что при росте сложности роли и плейбуки
распухают очень быстро, и поддерживать их очень сложно. Кроме того, применение нескольких разных инструментов(а некоторые
умельцы объединяют terraform и ansible) усложняет код еще быстрее(!). Удержать это в голове - нетривиальная задача.
А внятно передать поддержку практически невозможно.
* Если мне вдруг под нагрузкой придется поменять число нод, занимающихся одной задачей, то для каждой новой ноды придется
сделать отдельную запись в terraform и отдельно накатить на нее код, при этом каждый дроплет требует установленной
операционной системы. В идеале еще неплохо бы сделать внятный service-discovery
чтобы новая нода зарегистрировалась и подтянула конфигурацию. Но это уже розовые мечты какие-то.
* Тестирование сложной инфраструктуры с ansible-ролями на борту - отдельный квест, который не окупается совсем.
* Это отдельная боль всех опсов - любители подебажить на проде. Кто-то зашел, что-то сделал, оставил как есть. Ансибл
никогда не узнает, терраформу плевать. В логи не полезешь, пока пользователь не позвонит. А потом ты просто дропнешь эту
машину, и будешь ждать, пока не позвонит разработчик, и не потребует воскресить машину, которую ты только удалил.
--

=== !
image::images/the_roof_is_on_fire.jpg[]

[.notes]
--
Но это, на самом деле, очень отдаленное описание имеющихся проблем. Давайте посмотрим на несколько подробностей:
--

=== !
Оставь меня, я задержу их.
----
resource "digitalocean_droplet" "pgdb-dev" {
    image = "31754481"
    name = "pgdb-dev"
    region = "ams2"
    size = "s-2vcpu-2gb"
    private_networking = "true"
    resize_disk = "false"
    ssh_keys = ["${var.ssh_keys}"]
    user_data = "${file("minimal.conf")}"
}
----
[%step]
* Ах, если бы только ноды.

[.notes]
--
Здесь мы видим создание дроплета в digitalOcean. Для каждого дроплета необходимо указать образ ОС,
с которой он будет запущен, причем просто каким-нибудь Убунту16.04 дело не обойдется. Вы пробовали спустя месяц-два
сделать terraform plan? Как оказалось, у DO образы обновляются, и для старых образов приходится использовать цифры.
А если ты в спешке сделаешь apply, не посмотрев, сколько дроплетов у тебя пересобирается - тебя точно ждет бессонная ночь.
Продолжим. Также для каждого дроплета указывается регион и размер. С регионом понятно, он вряд ли куда-то переедет.
Но размер - вещь жесткая, и если мне нужна машинка получше - терраформ не будет заморачиваться, и убьет ее.
Вместе со всем содержимым. Если оно не внешнем волюме, разумеется. А танцы с почти ручным подключением волюмов в терраформе
это отдельный вид удовольствия.
--


=== !
Посыпьте их пеплом
----
variable "eps_names" { default = ["epsilon400", 
                                  "epsilon401", 
                                  "epsilon402", 
                                  "epsilon403", 
                                  "epsilon404",
                                  "epsilon405"] }
----
[%step]
* Когда в твою инфраструктуру попадает цикл.

[.notes]
--
Идем дальше. Вот этой конструкцией поддерживается масштабирование. Да, в этом списке находятся имена машин,
которые попадают в создание дроплетов. Указываем эту переменную в качестве источника данных, и дроплеты клепаются
один за другим. Выглядит довольно изящно, пока не начинаешь применять на практике.
--

=== Ansible-fu?
[%step]
* Управление inventory для ansible
* Соблюдение идемпотентности.
* Конфигурационный ад.
* Управление сервисами при обновлении.
* Зависимость от операционной системы.
* Создание внутренней сети с настройкой ip-tables

[.notes]
--
Закончили с терраформом хотя бы на минуту. Ведь он - только часть наследия, с которым приходилось иметь дело.
На арену выходит Ansible, со своими болезнями. Здесь тебе и провайдер-ориентированное управление динамическим inventory,
которое из коробки работает для AWS EC2, а для DigitalOcean мы где-то нашли решение.
Когда садишься конфигурировать машину, быстро зашиваешься в десятках ролей - тут тебе роль для установки hostname, тут -
для установки клиента заббикса, там тебе нужно настроить iptables, здесь - просто сконфигурировать 3 сетевых интерфейса,
все это должно проходить ямл-линтер, ансибл-линтер, соблюдать идемпотентность. Яркий пример - установка node.js.
В оригинальной документации для установки node.js мы должны скачать баш-скрипт с сайта и запустить его в командной оболочке.
Это делается предельно просто - с помощью одного-единственного пайпа. Но ансибл-линт не пропускает эту ерунду, ему не нравится.
Конфигурация прокси через ansible - отдельный формат удовольствия. В оригинальной nginx-роли локейшны задаются в ямле.
Приправьте это еще и попыткой хоть сколько-нибудь адаптировать роли хотя бы между операционными системами(Ubuntu и Centos),
и обычный плейбук для какого-нибудь сервера бд начнет представлять собой монстра о десяти конфигах и 300-500 строк роли.
--

=== !
Когда каждый ansible-playbook - произведение искусства.
----
---
- name: configure backoffice server
... 10 more lines
  roles:
    - role: do_hostname
... 20 more lines
    - role: backoffice
  tasks:
... 50 more lines
    - name: Reload nginx
      service:
        name: nginx
        state: reloaded
----
[%step]
* Долго, дорого, будет цениться после смерти автора(нет).

[.notes]
--
Нет, я искренне люблю ansible. Но для маленькой команды поддержка инфраструктуры и деплоймента через него - настоящее
искусство. То есть долго, дорого, и будет цениться после смерти автора. А вот при жизни его будут вспоминать очень
недобрыми словами, особенно если что-то сломается. Правда, нет худа без добра - стараниями моего коллеги Ивана Пономарева
с прошлого девупса жизнь стала чуть полегче. Правда, настройка /etc/hosts молекулой в докере все равно не тестируется.
--
